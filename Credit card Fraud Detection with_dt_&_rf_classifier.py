# -*- coding: utf-8 -*-
"""Prjt on Credit Card Fraud Detection with DT & RF Classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zH2wRqezH5MEXqCNPCDhVfxX2OgS8WGL

# Steps
1. Import libraries
2. Import the Dataset
3. Perform the Data Analysis (DM,
DC, DE,DV, EDA)
4. Data Preprocessing - Feature
Engineering (Encoders, Scaling,
Feature Importance/Selection, Hyper
Parameter Tuning, etc.)
5. Spliting of data into sets - CV
6. Model Selection
7. Train the model
8. Test the model
9. Performance metric - Confusion matrix, Accuracy score

# 1. Importing the libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re
from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, RandomizedSearchCV # RandSCV For hyperparameter tuning  which comes in model selection
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier #Model
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier #Models, #Extratrees to identify the important features

"""# Importing the Data sets"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("mlg-ulb/creditcardfraud")

print("Path to dataset files:", path)

import os

# List files in the specified directory
for dirname, _, filenames in os.walk('/kaggle/input/creditcardfraud'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

df = pd.read_csv('/kaggle/input/creditcardfraud/creditcard.csv')

"""# Data Analysis"""

df.head()

df.shape

df.info()

df.describe()

df.columns

df.Class.value_counts()

display(df.corr().T)

#To see the co relation to see in graph
plt.figure(figsize=(40,40))
sns.heatmap(df.corr().T, annot=True, cmap='Greens')

"""# Feature Importance/Slection"""

#Capital X is the feature matrix and y represents the target matrix
X = df.iloc[:,:-1] #all rows, all columns except the last one
y = df.iloc[:,-1]  #allrows, and only the last column

model = ExtraTreesClassifier()

model.fit(X,y)

model.feature_importances_

plt.figure(figsize=(10,10))
feat = pd.Series(model.feature_importances_, index=X.columns) #X for all the features
feat.nlargest(18).plot(kind='barh')
plt.grid()

cols = ['V17', 'V14', 'V12', 'V11', 'V16', 'V10', 'V18', 'V4', 'V3', 'V9', 'V7',
       'V21', 'Time', 'V27', 'V8', 'V1', 'V5', 'V2']
X_new = X[cols]

X_new.head(1)

feat = pd.Series(model.feature_importances_, index=X.columns) #X for all the features
plots = feat.nlargest(18)

plots.index

X.shape

X_new.shape

"""# Splitting the data into sets"""

skf = StratifiedKFold(n_splits=10)

#to grab the index values
for train_index, test_index in skf.split(X,y):
  X_train, X_test = X.iloc[train_index], X.iloc[test_index]
  y_train, y_test = y.iloc[train_index], y.iloc[test_index]

for train_index, test_index in skf.split(X,y):
  X_new_train, X_new_test = X_new.iloc[train_index], X_new.iloc[test_index]
  y_new_train, y_new_test = y.iloc[train_index], y.iloc[test_index]

X_train.shape

X_new_train.shape

"""# Model Selection"""

decision = DecisionTreeClassifier()
randomf = RandomForestClassifier()

"""# Hyper Parameter Tuning for Random Forrest Classifier"""

n_estimators = [int(i) for i in np.linspace(100,1200,12)]
max_features = ['auto', 'sqrt']
max_depth = [int(i) for i in np.linspace(5,30,5)]
min_samples_split = [2,5,10,15,100]
min_samples_leaf = [1,2,5,10]

#Entire dictionary for all the features

parameters = {'n_estimators': n_estimators,
               'max_features': max_features,
               'max_depth': max_depth,
               'min_samples_split': min_samples_split,
               'min_samples_leaf': min_samples_leaf}

parameters

rf_model = RandomizedSearchCV(estimator=randomf,
                              param_distributions=parameters,
                              scoring='neg_mean_squared_error',
                              cv=5, verbose=2, random_state=42, n_jobs=1)

randomf.fit(X_train, y_train)

y_pred = randomf.predict(X_test)

accuracy_score(y_test, y_pred)